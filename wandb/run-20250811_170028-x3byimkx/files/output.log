Episode 1/2000 | Total reward: -200.0
Episode 2/2000 | Total reward: -200.0
Episode 3/2000 | Total reward: -200.0
Episode 4/2000 | Total reward: -200.0
Episode 5/2000 | Total reward: -200.0
Episode 6/2000 | Total reward: -200.0
Traceback (most recent call last):
  File "/home/vijay/Desktop/rp2/cql/testing.py", line 186, in train_sweep
    l=2,
  File "/home/vijay/Desktop/rp2/cql/testing.py", line 122, in run_training
    next_action1 = np.argmax([q_value_w1(next_state, a) for a in range(n_actions)])
  File "/home/vijay/Desktop/rp2/cql/testing.py", line 122, in <listcomp>
    next_action1 = np.argmax([q_value_w1(next_state, a) for a in range(n_actions)])
  File "/home/vijay/Desktop/rp2/cql/testing.py", line 95, in q_value_w1
    return np.dot(weights_w1[action], phi(state))
  File "/home/vijay/Desktop/rp2/cql/testing.py", line 71, in phi
    diffs = rbf_centers - state
ValueError: input operand has more dimensions than allowed by the axis remapping
